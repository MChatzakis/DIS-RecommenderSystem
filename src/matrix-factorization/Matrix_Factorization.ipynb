{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5cdb5bd",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "This notebook implements matrix factorization for the MovieLens dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fdb6a6",
   "metadata": {},
   "source": [
    "## Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe6a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0d202",
   "metadata": {},
   "source": [
    "## Section 1: Load the Movielens data, do the needed preprocessing and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f49a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the data paths \n",
    "current_directory = os.getcwd()\n",
    "general_path = os.path.join(current_directory, 'project2_Data')\n",
    "\n",
    "movies_path = os.path.join(general_path, 'movies.csv')\n",
    "links_path = os.path.join(general_path, 'links.csv')\n",
    "tags_path = os.path.join(general_path, 'tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d23e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test ratings sets \n",
    "training_path = os.path.join(general_path, 'train_ratings.csv')\n",
    "test_path = os.path.join(general_path, 'test_set_no_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09b33a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres  \\\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "\n",
       "   imdbId  tmdbId  \n",
       "0  114709   862.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(movies_path)\n",
    "links = pd.read_csv(links_path)\n",
    "\n",
    "movies = pd.concat([movies,links],axis=1)   # concatenate the two infromation dataframes for the movies\n",
    "movies = movies.loc[:, ~movies.columns.duplicated()] # remove the duplicate columns \n",
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09dc6b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_tag_id</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>[funny, Highly quotable, will ferrell]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_tag_id  movieId                                     tag\n",
       "0            2    60756  [funny, Highly quotable, will ferrell]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pd.read_csv(tags_path)\n",
    "tags.rename(columns={'userId':'user_tag_id'},inplace=True)\n",
    "grouped_tags = tags.groupby(['user_tag_id', 'movieId']).agg(list).reset_index()\n",
    "grouped_tags.drop(columns='timestamp',inplace=True)\n",
    "grouped_tags.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c3dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training dataset \n",
    "train = pd.read_csv(training_path)\n",
    "train.drop(columns='timestamp',inplace=True)\n",
    "merged_train = train.merge(movies,on='movieId',how='left')\n",
    "\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "#Add the corresponding tags for each user-movieid combination\n",
    "merged_full = pd.merge(merged_train, grouped_tags, how='left', left_on=['userId', 'movieId'], right_on=['user_tag_id', 'movieId'])\n",
    "merged_full.drop(columns='user_tag_id',inplace=True)\n",
    "merged_full['rating_count_per_user']=merged_full.groupby('userId')['rating'].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fcdc2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>rating_count_per_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>509</td>\n",
       "      <td>7347</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Secret Window (2004)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>363988</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326</td>\n",
       "      <td>71462</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cove, The (2009)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>1313104</td>\n",
       "      <td>23128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>2115</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Indiana Jones and the Temple of Doom (1984)</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>87469</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>610</td>\n",
       "      <td>1127</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Abyss, The (1989)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>96754</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462</td>\n",
       "      <td>2409</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Rocky II (1979)</td>\n",
       "      <td>Action|Drama</td>\n",
       "      <td>79817</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                                        title  \\\n",
       "0     509     7347     3.0                         Secret Window (2004)   \n",
       "1     326    71462     4.0                             Cove, The (2009)   \n",
       "2      57     2115     3.0  Indiana Jones and the Temple of Doom (1984)   \n",
       "3     610     1127     4.0                            Abyss, The (1989)   \n",
       "4     462     2409     2.0                              Rocky II (1979)   \n",
       "\n",
       "                             genres   imdbId   tmdbId  tag  \\\n",
       "0                  Mystery|Thriller   363988   1586.0  NaN   \n",
       "1                       Documentary  1313104  23128.0  NaN   \n",
       "2          Action|Adventure|Fantasy    87469     87.0  NaN   \n",
       "3  Action|Adventure|Sci-Fi|Thriller    96754   2756.0  NaN   \n",
       "4                      Action|Drama    79817   1367.0  NaN   \n",
       "\n",
       "   rating_count_per_user  \n",
       "0                    374  \n",
       "1                    126  \n",
       "2                    383  \n",
       "3                   1044  \n",
       "4                    366  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d682f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user IDs: 610\n",
      "Number of unique movie IDs: 8983\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique user IDs: {merged_full['userId'].unique().size}\")\n",
    "print(f\"Number of unique movie IDs: {merged_full['movieId'].unique().size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b52f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    80668.000000\n",
       "mean       483.686914\n",
       "std        520.633681\n",
       "min         13.000000\n",
       "25%        115.000000\n",
       "50%        301.000000\n",
       "75%        679.000000\n",
       "max       2122.000000\n",
       "Name: rating_count_per_user, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_full['rating_count_per_user'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cf7a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of ratings per user: 483.69\n"
     ]
    }
   ],
   "source": [
    "average_ratings_per_user = merged_full['rating_count_per_user'].mean()\n",
    "print(f\"Average number of ratings per user: {average_ratings_per_user:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed4769",
   "metadata": {},
   "source": [
    "## Section 2: Matrix Factorization Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca15a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    \n",
    "    def __init__(self, rating_matrix, scale=0.03, num_features=400, l_rate=0.005, lambda_=0.1, num_iterations=400):\n",
    "        \n",
    "        '''\n",
    "        Parameters:\n",
    "        rating_matrix: The user-item rating matrix\n",
    "        scale: Scaling factor for initializing user and item vectors\n",
    "        num_features: Number of latent factors for user and item vectors\n",
    "        l_rate: Learning rate for gradient descent\n",
    "        lambda_: Regularization parameter to prevent overfitting\n",
    "        num_iterations: Number of iterations for training the model\n",
    "            \n",
    "        '''\n",
    "        self.rating_matrix = rating_matrix\n",
    "        self.scale = scale\n",
    "        self.num_features = num_features\n",
    "        self.l_rate = l_rate  \n",
    "        self.lambda_ = lambda_  \n",
    "        self.num_iterations = num_iterations\n",
    "        #Indices of non-zero elements in the rating matrix\n",
    "        self.non_zero_row_ind, self.non_zero_col_ind = rating_matrix.nonzero()   #Non-zero indices\n",
    "        self.num_pairs= len(rating_matrix[np.where(rating_matrix != 0)])  # Number of non-zero entries in the rating matrix \n",
    "        self.indices = list(range(self.num_pairs))   # Indices of the pairs of rating matrix \n",
    "        self.losses = []                             # To store training losses\n",
    "        \n",
    "        self.wait = 10\n",
    "        self.no_change = 10       \n",
    "        self.early_stopping = False\n",
    "\n",
    "        # Initialize Bias Values\n",
    "        self.user_biases = np.zeros(self.rating_matrix.shape[0])\n",
    "        self.item_biases = np.zeros(self.rating_matrix.shape[1])\n",
    "        \n",
    "        # Initialize user & item vectors        \n",
    "        self.user_features = np.random.normal(scale=self.scale, size=(self.rating_matrix.shape[0], self.num_features))\n",
    "        self.item_features = np.random.normal(scale=self.scale, size=(self.rating_matrix.shape[1], self.num_features))\n",
    "        # Compute global bias\n",
    "        self.global_bias = np.mean(self.rating_matrix[np.where(self.rating_matrix != 0)])        \n",
    "        \n",
    "    def predict(self, u, i):\n",
    "        return  self.global_bias + self.user_biases[u] + self.item_biases[i] + self.user_features[u] @ self.item_features[i]\n",
    "    \n",
    "    def fit(self, ):\n",
    "        '''\n",
    "        Train the matrix factorization model using stochastic gradient descent.\n",
    "        '''\n",
    "        self.now = time.time()\n",
    "        \n",
    "        for epoch in range(1, self.num_iterations):\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "            \n",
    "            if self.early_stopping == False:\n",
    "                \n",
    "                for index in self.indices:\n",
    "                    # Extracting user item information indices in which we have a rating\n",
    "                    u, i = self.non_zero_row_ind[index], self.non_zero_col_ind[index]\n",
    "                    pred_rat = self.predict(u, i)\n",
    "                    \n",
    "                    error = self.rating_matrix[u, i] - pred_rat\n",
    "                    \n",
    "                    # Update biases\n",
    "                    self.user_biases[u] += self.l_rate * (error - self.lambda_ * self.user_biases[u])\n",
    "                    self.item_biases[i] += self.l_rate * (error - self.lambda_ * self.item_biases[i])\n",
    "\n",
    "                    # Update User and item Vectors\n",
    "                    self.user_features[u, :] += self.l_rate * (error * self.item_features[i, :] - self.lambda_ * self.user_features[u, :])\n",
    "                    self.item_features[i, :] += self.l_rate * (error * self.user_features[u, :] - self.lambda_ * self.item_features[i, :])\n",
    "                \n",
    "                # Calculate epoch error \n",
    "                for index in self.indices:\n",
    "                    # Extracting user item information indices in which we have a rating\n",
    "                    u, i = self.non_zero_row_ind[index], self.non_zero_col_ind[index]\n",
    "                    pred_rat = self.predict(u, i)\n",
    "                    epoch_loss += (self.rating_matrix[u, i] - pred_rat) ** 2\n",
    "                avg_loss = epoch_loss / self.num_pairs\n",
    "                self.losses.append(avg_loss)\n",
    "                \n",
    "                # Check for early stopping \n",
    "                if len(self.losses)>1 and (self.losses[-2] - self.losses[-1]) <= 1e-3:\n",
    "                    if self.wait == self.no_change:\n",
    "                        self.early_stopping = True\n",
    "                    self.wait += 1\n",
    "                else:\n",
    "                    self.wait = 0\n",
    "                    \n",
    "        temp = np.round(time.time() - self.now, 3)            \n",
    "        print(f\"Fitted in {temp} seconds.\")\n",
    "        \n",
    "    def loss_plot(self, ):\n",
    "        '''\n",
    "        Plot the training Loss vs. num_iterations.\n",
    "        '''\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        plt.plot(range(1, 1 + len(self.losses)), self.losses, marker='o')\n",
    "        plt.title(\"Training Loss vs. Iterations\", fontsize=20)\n",
    "        plt.xlabel('Number of iterations', fontsize=18)\n",
    "        plt.ylabel('Error', fontsize=18)\n",
    "        plt.xticks(range(1, self.conv_epoch_num + 5), fontsize=15, rotation=90)  # There's no variable named 'conv_epoch_num'\n",
    "        plt.yticks(np.linspace(min(self.losses), max(self.losses), 15), fontsize=15)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40c761",
   "metadata": {},
   "source": [
    "## Section 3: Create a validation set by masking the training set and retaining all user IDs in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eebffb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 64423\n",
      "Validation set length: 16245\n"
     ]
    }
   ],
   "source": [
    "### For the validation set we masked 40 last ratings for each userId \n",
    "def get_mask_indexes(data, mask_rate=40):\n",
    "    mask_indexes = []\n",
    "    users = data['userId'].unique()\n",
    "    \n",
    "    for user_id in users:\n",
    "        #If one user have less than 40 ratings which is the case for around 7% entries we just take the last 10 ratings \n",
    "        #So this way we ensure that in validation set we dont have unseen user Ids\n",
    "        if len(data[data['userId'] == user_id])<=40:\n",
    "            mask_indexes += data[data['userId'] == user_id].iloc[-5:].index.tolist()         \n",
    "        else:\n",
    "            mask_indexes += data[data['userId'] == user_id].iloc[-mask_rate:].index.tolist()\n",
    "    \n",
    "    return mask_indexes\n",
    "\n",
    "masked_indexes = get_mask_indexes(merged_full)\n",
    "training_set =  merged_full.drop(masked_indexes)\n",
    "validation_set = merged_full.loc[masked_indexes]\n",
    "print(f\"Training set length: {len(training_set)}\") \n",
    "print(f\"Validation set length: {len(validation_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc9a816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>rating_count_per_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71664</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71775</th>\n",
       "      <td>509</td>\n",
       "      <td>28</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Persuasion (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>114117</td>\n",
       "      <td>17015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating              title  \\\n",
       "71664     509        1     4.0   Toy Story (1995)   \n",
       "71775     509       28     3.5  Persuasion (1995)   \n",
       "\n",
       "                                            genres  imdbId   tmdbId  tag  \\\n",
       "71664  Adventure|Animation|Children|Comedy|Fantasy  114709    862.0  NaN   \n",
       "71775                                Drama|Romance  114117  17015.0  NaN   \n",
       "\n",
       "       rating_count_per_user  \n",
       "71664                    374  \n",
       "71775                    374  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d212ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>rating_count_per_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>509</td>\n",
       "      <td>7347</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Secret Window (2004)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>363988</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326</td>\n",
       "      <td>71462</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cove, The (2009)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>1313104</td>\n",
       "      <td>23128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                 title            genres   imdbId  \\\n",
       "0     509     7347     3.0  Secret Window (2004)  Mystery|Thriller   363988   \n",
       "1     326    71462     4.0      Cove, The (2009)       Documentary  1313104   \n",
       "\n",
       "    tmdbId  tag  rating_count_per_user  \n",
       "0   1586.0  NaN                    374  \n",
       "1  23128.0  NaN                    126  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ff73b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(validation_set.userId.values ).issubset(training_set.userId.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d5748",
   "metadata": {},
   "source": [
    "## Section 4: Generate the Training Matrix and Fine-tune the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f149759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user_movie_matrix for the training/validation set\n",
    "\n",
    "def create_matrix(X_train,X_val):\n",
    "\n",
    "    user_ids = np.unique(np.concatenate([X_train['userId'].values, X_val['userId'].values]))\n",
    "    movie_ids = np.unique(np.concatenate([X_train['movieId'].values, X_val['movieId'].values]))\n",
    "    user_movie_matrix = np.zeros((len(user_ids), len(movie_ids)))\n",
    "\n",
    "    user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "    movie_id_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "    for index, row in X_train.iterrows():\n",
    "        user_index = user_id_to_index[row['userId']]\n",
    "        movie_index = movie_id_to_index[row['movieId']]\n",
    "        user_movie_matrix[user_index, movie_index] = row['rating']\n",
    "    return user_id_to_index,movie_id_to_index,user_movie_matrix\n",
    "\n",
    "train_user_id_to_index,train_movie_id_to_index,train_user_movie_matrix = create_matrix(training_set,validation_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61123973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'  \n",
    "# Define the hyperparameter values to explore\n",
    "num_features_values = [300,350,400,250,200]\n",
    "lambda_values = [0.1]\n",
    "lr_rate_factors = [0.005]\n",
    "scale_values = [0.03,0.035]\n",
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "        \n",
    "for num_features in num_features_values:\n",
    "    for l_rate in lr_rate_factors:\n",
    "        for lambda_ in lambda_values:\n",
    "            for scale in scale_values:\n",
    "\n",
    "                # Create and fit the MatrixFactorization model with current hyperparameters\n",
    "                model = MatrixFactorization(train_user_movie_matrix,scale=scale,l_rate=l_rate, num_features=num_features, lambda_=lambda_)\n",
    "                model.fit()\n",
    "\n",
    "                # Make predictions on the validation set\n",
    "                preds = []\n",
    "                for index, row in validation_set.iterrows():\n",
    "                    user_id = row['userId']\n",
    "                    movie_id = row['movieId']\n",
    "\n",
    "                    user_index = train_user_id_to_index[user_id]\n",
    "                    movie_index = train_movie_id_to_index[movie_id]\n",
    "\n",
    "                    predicted_rating = model.predict(user_index, movie_index)\n",
    "                    preds.append(predicted_rating)\n",
    "\n",
    "                # Calculate RMSE for the current hyperparameters\n",
    "                rmse = np.sqrt(mean_squared_error(validation_set['rating'], preds))\n",
    "                print(f\"Hyperparameters: num_features={num_features}, lambda_={lambda_},lr={l_rate},scale={scale} - RMSE: {rmse}\")\n",
    "\n",
    "                # Update the best parameters if the current RMSE is lower\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_params = {'num_features': num_features,'lr':l_rate, 'lambda_': lambda_}\n",
    "        \n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ed159",
   "metadata": {},
   "source": [
    "## Generate the predictions for the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cb7ec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the function instead \n",
    "all_user_ids = np.unique(np.concatenate([train['userId'].values, test['userId'].values]))\n",
    "all_movie_ids = np.unique(np.concatenate([train['movieId'].values, test['movieId'].values]))\n",
    "user_movie_matrix = np.zeros((len(all_user_ids), len(all_movie_ids)))\n",
    "\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(all_user_ids)}\n",
    "movie_id_to_index = {movie_id: index for index, movie_id in enumerate(all_movie_ids)}\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    user_index = user_id_to_index[row['userId']]\n",
    "    movie_index = movie_id_to_index[row['movieId']]\n",
    "    user_movie_matrix[user_index, movie_index] = row['rating']\n",
    "user_movie_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9f98e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted in 246.984 seconds.\n"
     ]
    }
   ],
   "source": [
    "test_matrix = MatrixFactorization(user_movie_matrix)\n",
    "test_matrix.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72a1bc",
   "metadata": {},
   "source": [
    "#### Create the final csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "170139a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.064759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.393295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.605893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.835080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.733241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    rating\n",
       "0   0  3.064759\n",
       "1   1  3.393295\n",
       "2   2  2.605893\n",
       "3   3  3.835080\n",
       "4   4  3.733241"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['rating']=0.0\n",
    "for index, row in test.iterrows():\n",
    "    user_id = row['userId']\n",
    "    movie_id = row['movieId']\n",
    "\n",
    "    user_index = user_id_to_index[user_id]\n",
    "    movie_index = movie_id_to_index[movie_id]\n",
    "\n",
    "    # Assuming predict is a function that takes user and movie indices\n",
    "    predicted_rating = test_matrix.predict(user_index, movie_index)\n",
    "\n",
    "    # Update the 'predicted_rating' column with the predicted rating\n",
    "    test.at[index, 'rating'] = predicted_rating\n",
    "test.drop(columns=['userId','movieId'],inplace=True)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c622ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('predictions.csv', index=False)\n",
    "print(f\"CSV file '{csv_file}' has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
